{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "712f035d-b27f-4166-bba8-a087fddd8d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Asegurar que todas las columnas se muestren\n",
    "pd.set_option('display.max_rows', None)  # Mostrar todas las filas\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "c1a9bd92-73fc-49d3-8688-1d925f63064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = [\" \"]\n",
    "\n",
    "# Leer el archivo con estos valores tratados como nulos\n",
    "data = pd.read_csv(\"../01_Data/data.csv\", encoding=\"latin1\", na_values=null_values)\n",
    "\n",
    "data = data[data['RESFIN'] == 1]\n",
    "data = data.drop(columns = [\n",
    "    'ANIO','OMICAP200','CCDD','CCPP','CCDI','CONGLOMERADO',\n",
    "    'NSELUA','UA','RESFIN','P102_1','P105_N','P203','CODIGO',\n",
    "    'P223A','P214','P221_1','P221_2','P215','P204_COD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "02a68d26-07cf-4abc-828b-a018c2415ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if col.endswith('_ENT'):\n",
    "        base_name = col[:-4]  # Eliminar el sufijo '_ENT'\n",
    "        decimal_col = f\"{base_name}_DEC\"  # Buscar la columna con sufijo '_DEC'\n",
    "\n",
    "        if decimal_col in data.columns:\n",
    "            # Extraer partes enteras y decimales como strings\n",
    "            ent_part = data[col].astype(str).str.split(\".\").str[0]  # Solo parte entera\n",
    "            dec_part = data[decimal_col].astype(str).str.split(\".\").str[0]  # Solo parte decimal\n",
    "\n",
    "            # Crear nueva columna combinada (entera + decimal ajustada)\n",
    "            data[base_name] = pd.to_numeric(ent_part + \".\" + dec_part, errors='coerce')  # Parte entera como número\n",
    "\n",
    "            # Opcional: Eliminar las columnas originales _ENT y _DEC\n",
    "            data.drop([col, decimal_col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "715dd250-d983-43a4-bd92-b9e26931cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['NOMBREDD', 'NOMBREPV', 'NOMBREDI', 'REGION', 'DOMINIO', 'FACTOR',\n",
       "        'P101A', 'P102_2', 'P204_NOM', 'P204_TIPO', 'P205_N', 'P205_TOT',\n",
       "        'P206_INI_MES', 'P206_INI_ANIO', 'P207_FIN_MES', 'P207_FIN_ANIO',\n",
       "        'P208', 'P209_MES', 'P209_ANIO', 'P210_SUP_1', 'P210_SUP_2', 'P211_1',\n",
       "        'P211_2', 'P211_3', 'P211_4', 'P211_5', 'P211_6', 'P211_7', 'P211_8',\n",
       "        'P212', 'P213', 'P217_SUP_1', 'P217_SUP_2', 'P217_SUP_ha', 'P218',\n",
       "        'P218A', 'P218B', 'P219_CANT_1', 'P219_CANT_2', 'P219_UM',\n",
       "        'P219_UM_COD', 'P219_EQUIV_KG', 'P220_1_CANT_1', 'P220_1_CANT_2',\n",
       "        'P220_1_PREC_1', 'P220_1_PREC_2', 'P220_1_VAL', 'P220_1_PRE_KG',\n",
       "        'P220_2_PREC_1', 'P220_2_PREC_2', 'P220_2_VAL', 'P220_2_PRE_KG',\n",
       "        'P220_3A_PREC_1', 'P220_3A_PREC_2', 'P220_3A_VAL', 'P220_3A_PRE_KG',\n",
       "        'P220_3B_PREC_1', 'P220_3B_PREC_2', 'P220_3B_VAL', 'P220_3B_PRE_KG',\n",
       "        'P222_1', 'P222_2', 'P222_3', 'P222_4', 'P222_5', 'P222_6', 'P222_7',\n",
       "        'P223_1', 'P223_2', 'P223_3', 'P223_4', 'P223_5', 'P223_6', 'P223B_1',\n",
       "        'P223B_2', 'P223B_3', 'P223B_4', 'P223B_5', 'P223B_6', 'P223B_7',\n",
       "        'P223B_8', 'P220_2', 'P220_3', 'P220_3A', 'P220_3B', 'P220_4', 'P220_5',\n",
       "        'P220_6', 'P220_7', 'P220_8', 'P220_9', 'P220_10'],\n",
       "       dtype='object'),\n",
       " (105609, 92))"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "316649b5-d5c1-41c7-bca3-bd5c7d101f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P101A             100.000000\n",
      "P220_3A_PREC_2    100.000000\n",
      "P220_3A_PREC_1    100.000000\n",
      "P220_3A_VAL       100.000000\n",
      "P220_3B_VAL       100.000000\n",
      "P220_3B           100.000000\n",
      "P220_3A           100.000000\n",
      "P220_3B_PRE_KG    100.000000\n",
      "P220_3B_PREC_1    100.000000\n",
      "P220_3B_PREC_2    100.000000\n",
      "P220_3A_PRE_KG    100.000000\n",
      "P218A              86.508726\n",
      "P218B              86.508726\n",
      "P218               66.066339\n",
      "P223B_2            65.323978\n",
      "P223B_1            65.323978\n",
      "P223B_5            65.323978\n",
      "P223B_6            65.323978\n",
      "P223B_4            65.323978\n",
      "P223B_3            65.323978\n",
      "P223B_7            65.323978\n",
      "P223B_8            65.323978\n",
      "P220_3             55.961140\n",
      "P213               53.248303\n",
      "P220_1_VAL         51.648060\n",
      "P220_1_PREC_1      51.648060\n",
      "P220_1_PRE_KG      51.648060\n",
      "P223_4             51.648060\n",
      "P222_3             51.648060\n",
      "P223_3             51.648060\n",
      "P223_2             51.648060\n",
      "P223_1             51.648060\n",
      "P222_7             51.648060\n",
      "P222_6             51.648060\n",
      "P222_5             51.648060\n",
      "P222_4             51.648060\n",
      "P223_6             51.648060\n",
      "P222_2             51.648060\n",
      "P222_1             51.648060\n",
      "P223_5             51.648060\n",
      "P220_1_PREC_2      51.634804\n",
      "P220_2_PRE_KG      40.983250\n",
      "P220_2_PREC_2      40.983250\n",
      "P220_2_PREC_1      40.983250\n",
      "P220_2_VAL         40.983250\n",
      "P220_6             31.413989\n",
      "P220_2             17.212548\n",
      "P220_5              7.829825\n",
      "P210_SUP_2          0.583284\n",
      "P211_1              0.583284\n",
      "P211_2              0.583284\n",
      "P211_3              0.583284\n",
      "P211_4              0.583284\n",
      "P211_5              0.583284\n",
      "P211_6              0.583284\n",
      "P211_7              0.583284\n",
      "P209_ANIO           0.583284\n",
      "P209_MES            0.583284\n",
      "P210_SUP_1          0.583284\n",
      "P211_8              0.577602\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Total de filas en el DataFrame\n",
    "total_filas = len(data)\n",
    "\n",
    "# Calcular el porcentaje de valores nulos por columna\n",
    "nulos_por_columna = data.isnull().sum()\n",
    "porcentaje_nulos = (nulos_por_columna / total_filas) * 100\n",
    "\n",
    "# Filtrar columnas con valores nulos\n",
    "columnas_con_nulos = porcentaje_nulos[porcentaje_nulos > 0]\n",
    "\n",
    "# Mostrar el porcentaje de nulos por columna\n",
    "print(columnas_con_nulos.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "bba8e1c0-bdb1-4621-8810-fff651ccd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas con al menos 70% de valores nulos\n",
    "data = data.loc[:, porcentaje_nulos <= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "35f83c8c-4bf3-47a7-8f64-f9844a2f4834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores imputados: 252\n",
      "Filas eliminadas: 69520\n"
     ]
    }
   ],
   "source": [
    "# Variables predictoras y objetivo\n",
    "predictors = ['P217_SUP_1', 'P217_SUP_2', 'P217_SUP_ha']\n",
    "target = 'P218'\n",
    "group_column = 'P204_NOM'  # Columna para segmentar por cultivo\n",
    "\n",
    "# Contadores para resultados\n",
    "imputed_count = 0\n",
    "deleted_rows_count = 0\n",
    "\n",
    "# Iterar por cada tipo de cultivo\n",
    "for cultivo in data[group_column].dropna().unique():\n",
    "    # Filtrar datos para el cultivo actual\n",
    "    cultivo_data = data[data[group_column] == cultivo]\n",
    "    \n",
    "    # Separar datos para entrenamiento y predicción\n",
    "    train_data = cultivo_data.dropna(subset=predictors + [target])\n",
    "    test_data = cultivo_data[cultivo_data[target].isnull()]\n",
    "    \n",
    "    if len(train_data) > 10:  # Entrenar el modelo solo si hay suficientes datos\n",
    "        # Entrenar modelo de regresión\n",
    "        X_train = train_data[predictors]\n",
    "        y_train = train_data[target]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir valores para los datos faltantes\n",
    "        X_test = test_data[predictors].dropna()\n",
    "        if not X_test.empty:\n",
    "            predicted_values = model.predict(X_test)\n",
    "            predicted_values = np.round(predicted_values).astype(int)  # Redondear al entero más cercano\n",
    "            \n",
    "            # Imputar los valores predichos\n",
    "            data.loc[X_test.index, target] = predicted_values\n",
    "            imputed_count += len(predicted_values)\n",
    "            print(f\"Imputados {len(predicted_values)} valores en '{target}' para cultivo '{cultivo}'.\")\n",
    "    else:\n",
    "        # Si no hay suficientes datos, imputar con la mediana o eliminar\n",
    "        median_value = train_data[target].median()\n",
    "        if not np.isnan(median_value):\n",
    "            missing_before = data[target].isnull().sum()\n",
    "            data.loc[(data[group_column] == cultivo) & (data[target].isnull()), target] = median_value\n",
    "            missing_after = data[target].isnull().sum()\n",
    "            imputed_count += missing_before - missing_after\n",
    "        else:\n",
    "            # Eliminar filas si no se puede calcular la mediana\n",
    "            rows_to_delete = data[(data[group_column] == cultivo) & (data[target].isnull())].index\n",
    "            deleted_rows_count += len(rows_to_delete)\n",
    "            data = data.drop(rows_to_delete)\n",
    "\n",
    "print(f\"Valores imputados: {imputed_count}\")\n",
    "print(f\"Filas eliminadas: {deleted_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "182e9710-cd4d-46d6-884a-1c8d42404cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores imputados: 99166\n",
      "Filas eliminadas: 5704\n"
     ]
    }
   ],
   "source": [
    "# Columnas a procesar\n",
    "columns_to_process = [\n",
    "    'P220_1_PREC_1', 'P220_1_PRE_KG', 'P220_1_VAL', 'P220_1_PREC_2', \n",
    "    'P220_2_PRE_KG', 'P220_2_VAL', 'P220_2_PREC_1', 'P220_2_PREC_2',\n",
    "    'P220_6'\n",
    "]\n",
    "group_column = 'P204_NOM'  # Columna para segmentar por tipo de cultivo\n",
    "\n",
    "# Contadores para resultados\n",
    "imputed_count = 0\n",
    "deleted_rows_count = 0\n",
    "\n",
    "# Iterar por cada columna a procesar\n",
    "for col in columns_to_process:\n",
    "    # Iterar por cada tipo de cultivo\n",
    "    for cultivo in data[group_column].dropna().unique():\n",
    "        # Filtrar datos para el cultivo actual\n",
    "        cultivo_data = data[data[group_column] == cultivo]\n",
    "        \n",
    "        # Validar que haya datos suficientes para calcular la mediana\n",
    "        if not cultivo_data[col].dropna().empty:  # Verificar que el subconjunto no esté vacío\n",
    "            # Calcular la mediana de la columna para este cultivo\n",
    "            median_value = cultivo_data[col].median()\n",
    "            \n",
    "            # Reemplazar los valores nulos con la mediana\n",
    "            missing_before = data[col].isnull().sum()\n",
    "            data.loc[(data[group_column] == cultivo) & (data[col].isnull()), col] = median_value\n",
    "            missing_after = data[col].isnull().sum()\n",
    "            imputed_count += missing_before - missing_after\n",
    "        else:\n",
    "            # Si no hay datos para calcular la mediana, eliminar las filas\n",
    "            rows_to_delete = data[(data[group_column] == cultivo) & (data[col].isnull())].index\n",
    "            deleted_rows_count += len(rows_to_delete)\n",
    "            data = data.drop(rows_to_delete)\n",
    "\n",
    "print(f\"Valores imputados: {imputed_count}\")\n",
    "print(f\"Filas eliminadas: {deleted_rows_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "ec1006eb-5ba4-44d5-906d-36ef6c83b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas donde P209_MES o P209_ANIO tienen valores nulos\n",
    "data = data.dropna(subset=['P209_MES', 'P209_ANIO'])\n",
    "\n",
    "# Rellenar los valores nulos con 0 en las columnas que comienzan con P222 y P223\n",
    "data[[col for col in data.columns if col.startswith('P222') or col.startswith('P223')]] = \\\n",
    "    data[[col for col in data.columns if col.startswith('P222') or col.startswith('P223')]].fillna(0)\n",
    "\n",
    "# Reemplazar nulos en P220_3_ENT y P220_3_DEC con 0\n",
    "data[['P220_3']] = data[['P220_3']].fillna(0)\n",
    "\n",
    "# Reemplazar nulos en P213 con la moda\n",
    "moda_p213 = data['P213'].mode()[0]  # Calcular la moda\n",
    "data['P213'] = data['P213'].fillna(moda_p213)\n",
    "\n",
    "# Imputar valores nulos con la mediana\n",
    "mediana = data['P220_5'].median()  # Calcular la mediana\n",
    "data['P220_5'] = data['P220_5'].fillna(mediana)  # Reemplazar nulos con la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "4b5c6e2c-7f71-4514-a873-02f37ca78897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), (30094, 79))"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum(), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "e282d74c-f78d-493a-80ab-73e70c18e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../01_Data/clean_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
